{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2769e4e",
   "metadata": {},
   "source": [
    "# Introduction to Active Learning (AL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3941835",
   "metadata": {},
   "source": [
    "This notebook introduces an Active Learning (AL) model to predict properties using iterative sampling and model training\n",
    "\n",
    "First, we need to install and import the required libraries. One of these libraries is `modAL` (https://modal-python.readthedocs.io/en/latest/content/models/ActiveLearner.html), an active learning framework for Python 3. Built on top of `scikit-learn`, it enables you to rapidly create active learning workflows.\n",
    "\n",
    "In this notebook, we will:\n",
    "- Explore the principles of active learning\n",
    "- Use the modAL library to implement an AL model\n",
    "\n",
    "**NB!**\n",
    "    ðŸ“‚ Note:\n",
    "    To run this notebook successfully, make sure you download the required data files from the GitHub repository: https://github.com/lmoranglez/SummerSchool.git and save them in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a04014a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell once to install the required libraries\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install pandas==2.2.3 scikit-learn==1.6.1 matplotlib==3.10.1 seaborn==0.13.2 rdkit==2024.9.6\n",
    "#!{sys.executable} -m pip install modAL-python==0.4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1a0ccc-830d-4577-9b0d-fe0802f8aa8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the libraries in your ipython kernel\n",
    "#!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490fc3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries to import\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import uncertainty_sampling\n",
    "from modAL.utils.selection import multi_argmax\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58377d50-a087-4c06-b683-58e32ffaeaa3",
   "metadata": {},
   "source": [
    "# Part 1: EDBO+: an active learning platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd80727-82eb-4cd1-8fd3-544c50a52cd6",
   "metadata": {},
   "source": [
    "### 1.1. Visualize EDBO+ results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81b11e4-7483-4496-8828-b884ddceb0f2",
   "metadata": {},
   "source": [
    "**EDBO+** is an open-source, Bayesian theory-based platform for single- and multi-objective active learning, with an accompanying web application (https://www.edbowebapp.com/). It is used for reaction condition screening.\n",
    "\n",
    "To illustrate its utility, we begin with a single-objective optimization task: **maximizing reaction yield**.\n",
    "\n",
    "In the bellow cells, we will visualize the hypothetical chemical space of possible conditions. Later, we will load and analyze a pre-optimized dataset that has been generated using the AL strategy implemented in EDBO+.\n",
    "\n",
    "*Chemical Space Features*\n",
    "- Temperature (Â°C): [0, 20, 40, 80, 100, 120, 140]\n",
    "- Concentration (M): [0.1, 0.2, 1.0, 1.2, 1.5, 1.6, 2.0]\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e581b-24b6-4bda-b554-71d0c20c3482",
   "metadata": {},
   "source": [
    "1.1.1. Define and load the chemical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580cafa-82c3-49db-8b66-b1b2d8c26c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the entire chemical space without label\n",
    "Temperature = [0, 20, 40, 80, 100, 120, 140]\n",
    "Concentration = [0.1, 0.2, 1.0, 1.2, 1.5, 1.6, 2.0]\n",
    "\n",
    "combinations = []\n",
    "# Table with all the potential combinations \n",
    "for j in Temperature:\n",
    "    for k in Concentration:\n",
    "        combinations.append({\n",
    "                            'Temperature':j,\n",
    "                            'Concentration':k})\n",
    "        \n",
    "chemicalspace = pd.DataFrame(combinations)\n",
    "chemicalspace['Yield'] = np.nan  # Initialize as empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f632807-6811-400a-bcbb-5ab051bf4e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data generated after the optimization process\n",
    "# NB! Ensure these .csv files are in the same folder as the Jupyter notebook.\n",
    "\n",
    "# Iteration refers to the data provided after the oracle labels\n",
    "iteration1 = pd.read_csv(\"example1_label.csv\")\n",
    "iteration2 = pd.read_csv(\"example2_label.csv\")\n",
    "iteration3 = pd.read_csv(\"example3_label.csv\")\n",
    "iteration4 = pd.read_csv(\"example4_label.csv\")\n",
    "iteration5 = pd.read_csv(\"example5_label.csv\")\n",
    "\n",
    "# Predictions obtained once the training query strategy starts\n",
    "prediction1 = pd.read_csv(\"pred_example1.csv\")\n",
    "prediction2 = pd.read_csv(\"pred_example2.csv\")\n",
    "prediction3 = pd.read_csv(\"pred_example3.csv\")\n",
    "prediction4 = pd.read_csv(\"pred_example4.csv\")\n",
    "prediction5 = pd.read_csv(\"pred_example5.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94415cb",
   "metadata": {},
   "source": [
    "1.1.2. Visualize the hypothetical  chemical space *before* active learning begins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7471e2-87eb-4d7a-947f-3ce035253b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot functions to visualize the results generated by the EDBO+ platform\n",
    "def plot_single_heatmap(data: pd.DataFrame,  \n",
    "                       y_col: str = 'Yield',  # Can be 'Yield' or 'Yield_predicted_mean'\n",
    "                       title: str = None, \n",
    "                       figsize: tuple = (5, 4),\n",
    "                       is_prediction: bool = False): # if True, modifies labels for predicted values\n",
    "    \"\"\"\n",
    "    Create a heatmap for either actual Yield or predicted Yield values.\n",
    "    \"\"\"\n",
    "    # Validate input column\n",
    "    if y_col not in data.columns:\n",
    "        raise ValueError(f\"Column '{y_col}' not found in DataFrame\")\n",
    "    \n",
    "    # Pivot data\n",
    "    heatmap_data = data.pivot(index='Temperature', columns='Concentration', values=y_col)\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    ax = sns.heatmap(\n",
    "        heatmap_data,\n",
    "        annot=True,\n",
    "        fmt=\".1f\",\n",
    "        cmap='YlOrRd',\n",
    "        linewidths=1,\n",
    "        linecolor='black',\n",
    "        square=True,\n",
    "        cbar_kws={'label': f\"{'Predicted ' if is_prediction else ''}Yield (%)\", \n",
    "                 'shrink': 0.8},\n",
    "        vmin=0,\n",
    "        vmax=100,\n",
    "        annot_kws={'fontsize': 11}\n",
    "    )\n",
    "\n",
    "    default_title = f\"{'Predicted ' if is_prediction else ''}Yield\" \n",
    "    plt.title(title if title else default_title, fontsize=14, pad=20)\n",
    "    \n",
    "    # Axis labels\n",
    "    ax.set_xlabel('Concentration (M)', fontsize=12)\n",
    "    ax.set_ylabel('Temperature (Â°C)', fontsize=12)\n",
    "    \n",
    "    # Handle missing values\n",
    "    for y in range(heatmap_data.shape[0]):\n",
    "        for x in range(heatmap_data.shape[1]):\n",
    "            if pd.isna(heatmap_data.iloc[y, x]):\n",
    "                ax.text(x + 0.5, y + 0.5, 'N/A', \n",
    "                       ha='center', va='center', \n",
    "                       color='gray', fontstyle='italic')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return ax\n",
    "\n",
    "def plot_combined_results(iteration_data: pd.DataFrame, \n",
    "                        prediction_data: pd.DataFrame, \n",
    "                        x_var='Concentration', # variable to plot on x-axis ('Concentration' or 'Temperature')\n",
    "                        figsize=(10, 8), \n",
    "                        heatmap_title=None,  # title for heatmap, if you later add it\n",
    "                        lineplot_title=None): # title for line plot, if you later add it\n",
    "    \"\"\"\n",
    "    Create combined plot with heatmap and prediction lineplot.\n",
    "    \"\"\"\n",
    "    # Validate x_var input\n",
    "    if x_var not in ['Concentration', 'Temperature']:\n",
    "        raise ValueError(\"x_var must be either 'Concentration' or 'Temperature'\")\n",
    "    \n",
    "    # Set the other variable (y_var) based on x_var choice\n",
    "    y_var = 'Temperature' if x_var == 'Concentration' else 'Concentration'\n",
    "    \n",
    "    # Create figure with two subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
    "    \n",
    "    # --- First plot: Heatmap ---\n",
    "    iteration_data['Yield'] = iteration_data['Yield'].replace('PENDING', np.nan)\n",
    "    iteration_data['Yield'] = pd.to_numeric(iteration_data['Yield'], errors='coerce')\n",
    "    \n",
    "    heatmap_data = iteration_data.pivot(index='Temperature', columns='Concentration', values='Yield')\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(heatmap_data, \n",
    "                annot=True, \n",
    "                fmt=\".1f\", \n",
    "                cmap='YlOrRd',\n",
    "                mask=heatmap_data.isnull(),\n",
    "                linewidths=1,\n",
    "                linecolor='black',\n",
    "                square=True,\n",
    "                cbar_kws={'label': 'Yield (%)', 'shrink': 0.8},\n",
    "                vmin=0,\n",
    "                vmax=100,\n",
    "                annot_kws={'fontsize': 12},\n",
    "                ax=ax1)\n",
    "    \n",
    "    # Set titles\n",
    "    heatmap_title = heatmap_title or f'Yield Heatmap by Temperature and Concentration'\n",
    "    ax1.set_title(heatmap_title)\n",
    "    ax1.set_xlabel('Concentration (M)', fontsize=12)\n",
    "    ax1.set_ylabel('Temperature (Â°C)', fontsize=12)\n",
    "    \n",
    "    # --- Second plot: Line plot with uncertainty ---\n",
    "    prediction_data['Yield'] = prediction_data['Yield'].replace('PENDING', np.nan)\n",
    "    prediction_data['Yield'] = pd.to_numeric(prediction_data['Yield'], errors='coerce')\n",
    "    \n",
    "    ground_truth = prediction_data.dropna(subset=['Yield'])\n",
    "    predictions = prediction_data.copy()\n",
    "    \n",
    "    # Sort by x_var for proper line plotting\n",
    "    predictions = predictions.sort_values(x_var)\n",
    "    \n",
    "    # Predicted mean (blue line)\n",
    "    sns.lineplot(\n",
    "        data=predictions,\n",
    "        x=x_var,\n",
    "        y='Yield_predicted_mean',\n",
    "        color='blue',\n",
    "        label='Predicted Yield',\n",
    "        linewidth=2,\n",
    "        ax=ax2\n",
    "    )\n",
    "    \n",
    "    # Uncertainty band (mean Â± sqrt(variance))\n",
    "    ax2.fill_between(\n",
    "        predictions[x_var],\n",
    "        predictions['Yield_predicted_mean'] - np.sqrt(predictions['Yield_predicted_variance']),\n",
    "        predictions['Yield_predicted_mean'] + np.sqrt(predictions['Yield_predicted_variance']),\n",
    "        color='blue',\n",
    "        alpha=0.2,\n",
    "        label='Uncertainty (Â±Ïƒ)',\n",
    "    )\n",
    "    \n",
    "    # Ground truth points (red circles)\n",
    "    ax2.scatter(\n",
    "        ground_truth[x_var],\n",
    "        ground_truth['Yield'],\n",
    "        color='red',\n",
    "        s=80,\n",
    "        label='Ground Truth',\n",
    "        edgecolor='black',\n",
    "        zorder=10,\n",
    "    )\n",
    "    \n",
    "    # Set axis limits based on data range\n",
    "    x_min = predictions[x_var].min() - (0.1 * predictions[x_var].max())\n",
    "    x_max = predictions[x_var].max() * 1.1\n",
    "    ax2.set_xlim(x_min, x_max)\n",
    "    \n",
    "    # Set titles and labels\n",
    "    lineplot_title = lineplot_title or f\"Yield Predictions by {x_var.capitalize()} with Uncertainty\"\n",
    "    ax2.set_title(lineplot_title)\n",
    "    ax2.set_xlabel(x_var.capitalize())\n",
    "    \n",
    "    # Configure legend\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    ax2.legend(handles, labels, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig, (ax1, ax2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21ec960-12c5-4f9a-89db-72405432422d",
   "metadata": {},
   "source": [
    "Empty chemical space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1aa169-534e-4c0e-8d22-f16eb7453635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The initial chemical space is empty and contains no labels.\n",
    "ax = plot_single_heatmap(chemicalspace, \n",
    "                   y_col='Yield',\n",
    "                   is_prediction=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99ae50",
   "metadata": {},
   "source": [
    "Initial **(1)** labeled data introduced: target property distribution (left) and the model created with such (1) labeled data, where `Yield_predicted_mean` vs. `x_var` property ('Temperature' or 'Concentration') (right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b97296-b0da-48f9-9a52-24679dc9c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plot_combined_results(iteration1, prediction1, x_var='Temperature', figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b84030",
   "metadata": {},
   "source": [
    "**Iteration (2)** labeled data added: Target property distribution (left) and updated model using (2) labeled data points, with `Yield_predicted_mean` vs. `x_var` ('Temperature'/'Concentration') (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4cb4a1-8ee1-44c3-9dab-038c38c028c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plot_combined_results(iteration2, prediction2, x_var='Temperature', figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b8dc5a",
   "metadata": {},
   "source": [
    "**Iteration (3)** labeled data added: Target property distribution (left) and refined model using (3) labeled data points, showing `Yield_predicted_mean` vs. `x_var` ('Temperature'/'Concentration') (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0bfff2-8a7f-4919-a4a0-28b7215a7209",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plot_combined_results(iteration3, prediction3, x_var='Temperature', figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b062a1a1",
   "metadata": {},
   "source": [
    "**Iteration (4)** labeled data added: Target property distribution (left) and optimized model using (4) labeled data points, comparing `Yield_predicted_mean` vs. `x_var` ('Temperature'/'Concentration') (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0f5f41-7e5d-4343-967d-6e174d9aec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plot_combined_results(iteration4, prediction4, x_var='Temperature', figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16679c2e",
   "metadata": {},
   "source": [
    "**Iteration (5)** labeled data added: Target property distribution (left) and optimized model using (4) labeled data points, comparing `Yield_predicted_mean` vs. `x_var` ('Temperature'/'Concentration') (right)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a635e07-cb66-448b-9bfa-3a6e09892b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plot_combined_results(iteration5, prediction5, x_var='Temperature', figsize=(16,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdeccd8",
   "metadata": {},
   "source": [
    "**Predicted** yield heatmap. \\\n",
    "**NB!**: Only labeled points are verified. Other values are model estimates whose accuracy depends on their uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7a957",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_single_heatmap(prediction5, \n",
    "                   y_col='Yield_predicted_mean',\n",
    "                   is_prediction=True,\n",
    "                   title=\"Model Predictions (Iteration X) - Predicted Yield\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf381a1-255a-4edf-96e1-4ab6d118206a",
   "metadata": {},
   "source": [
    "### 1.2. Key Observations from Yield Heatmap Analysis\n",
    "\n",
    "**Temperature Dependence:**\n",
    "- Yield increase from 0-80Â°C\n",
    "- Maximum yield achieved at 40Â°C with 1.6M catalyst\n",
    "- Exponential decrease above 80Â°C suggests:\n",
    "  â€¢ Catalyst thermal decomposition\n",
    "  â€¢ Potential poisoning effects\n",
    "  â€¢ Competing side reactions becoming dominant\n",
    "\n",
    "**Catalyst Concentration (0.1-2.0M):**\n",
    "- No significant correlation with yield observed\n",
    "- Indicates either:\n",
    "  1) Catalyst saturation already at minimum concentration\n",
    "  2) Non-rate-limiting role in this concentration range\n",
    "\n",
    "**Recommended Next Steps:**\n",
    "1. Expand low concentration testing (0.01-0.1M)\n",
    "2. Conduct thermal stability studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40568c-3954-4196-bcc4-5b60e7172fc9",
   "metadata": {},
   "source": [
    "### 1.3. Next steps: customize and run your own EDBO+ optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d9645b-0e09-4228-8ca2-1d426dae44e5",
   "metadata": {},
   "source": [
    "Now that you've evaluated EDBO+ with a predefined example, you can explore new optimizations by modifying the parameters. Below are the steps to recreate the previous example with your own adjustments.\n",
    "\n",
    "Key Requirements for Visualization\n",
    "\n",
    "To use the previous plotting functions, maintain these exact variable names: `Temperature`, `Concentration` and `Yield`. However, you can modify the values of the `Temperature`, `Concentration` features (within the EDBO+ interface and in the cell of the definition of the chemical space above in section 1.1.1.), as well as  the objective of the `Yield` (maximize, minimize, or range).\n",
    "\n",
    "Web application (https://www.edbowebapp.com/).\n",
    "\n",
    "**Steps to follow:**\n",
    "\n",
    "Access the EDBO+ Web interface and, select Create New Scope `+ Build`.\n",
    "\n",
    "- Set the name of your scope to: `name`\n",
    "- `Add Features`:\n",
    "  - Temperature: # replace by your new suggestions, e.g. 0, 20, 40, 80, 100, 120, 140 \n",
    "  - Concentration: # replace by your new suggestions; e.g. 0.1, 0.2, 1.0, 1.2, 1.5, 1.6, 2.0\n",
    "    \n",
    "Click `Create scope`\n",
    "\n",
    "Run Optimization, to `Optimize` (*learner*), and select the previously defined scope: `name`, and then click on `Setup Optimizer`.\n",
    "\n",
    "- Select the features you want to use. Choose: `All`\n",
    "- Add Objectives:\n",
    "      `Yield`,\n",
    "      `maximize` (*define the query strategy*)\n",
    "- Number of experiments to run: `3` (*experiments to label*)\n",
    "- Click `Run optimizer` (*run the learner model to get predictions*)\n",
    "- Click `Download scope` (*this prompts the query to label*)\n",
    "    Label Experiments:\n",
    "- In the downloaded scope file, label queries with `PRIORITY = 1` and save it as name_request1 (name_request1.csv) (*label by oracle*)\n",
    "- There is also the buttom: `Download predictions`. In the first optimization, we do not have predictions because we first need to introduce some labels into the model. \n",
    "\n",
    "Iteration Process\n",
    "\n",
    "Once the first iteration is complete, proceed with additional iterations:\n",
    "\n",
    "- `Upload` the .csv with the updated results `name_request1` (name_request1.csv) as a new scope `name_1`\n",
    "- Repeat the optimization steps outline above\n",
    "- From now on, download both `Download scope` and `Download predictions`, naming them accordingly: name_request2.csv (for the data to label in the second iteration) and name_pred1.csv (for the predictions with the first set of labels), respectively.\n",
    "- Continue iterating as needed\n",
    "\n",
    "**NB!** Be aware that the names `Temperature`, `Concentration` and `Yield` must  use capitalized first letters! \\\n",
    "**NB!** Ensure all .csv files (e.g., name_request1.csv, name_request2.csv, etc.) are saved in the same directory as this Jupyter notebook. \\\n",
    "**NB!** In Section 1.1.1 (Define and Load Chemical Space), update: the chemical space parameters (if modified), and the file names to match your iteration numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d361f892-a9dc-418f-b454-c4350bc1bc99",
   "metadata": {},
   "source": [
    "# Part 2: Active Learning using modAL library\n",
    "\n",
    "To demonstrate the power of data-driven optimization, we apply AL to a chemical reaction dataset, using `surrogate models` to iteratively select the most informative experiments. This approach mirrors the logic of platforms like EDBO+ but is implemented here with customizable Python workflows.\n",
    "\n",
    "The dataset contains as features: `Temperature` and `Concentration` and as target property `Yield`.\n",
    "\n",
    "The dataset can be found as a csv file with the name `chemical_process_AL_TC.csv` in the github repository: \n",
    "\n",
    "**Methodology**\n",
    "Two models are going to be used to predict yields and guide AL: linear regression and Gaussian Process. \n",
    "\n",
    "**Active learning 1orkflow**\n",
    "\n",
    "        Initialization: Start with a small labeled subset (X_initial, y_initial).\n",
    "\n",
    "        Query Strategy:\n",
    "\n",
    "            For Linear Regression: Select points with the highest prediction error (MSE-based).\n",
    "\n",
    "            For GP: Prioritize points with highest uncertainty (standard deviation).\n",
    "\n",
    "        Iteration: Repeatedly query the \"oracle\" (e.g., new experiments) and retrain.\n",
    "\n",
    "**Visualization**\n",
    "Track performance (RÂ²) and training set growth across iterations to evaluate efficiency.\n",
    "\n",
    "**Goal**: assess how the model performance increases as long as we introduced the selected data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9c662c-7c81-4ce4-8305-a0d4c439db4f",
   "metadata": {},
   "source": [
    "### 2.1. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164c8c3-2cbf-438d-a283-5b7528ee1d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# If you want to suppress all warnings (not recommended unless necessary)\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76553d26-5339-4753-a3ef-15714e5754b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"chemical_AL_TC.csv\")\n",
    "\n",
    "# Display all columns in the dataframe\n",
    "print(data.columns.tolist())\n",
    "\n",
    "df_features = data.drop(columns=['Yield'])\n",
    "X = df_features.values\n",
    "y = data['Yield'].values\n",
    "\n",
    "print('Track the size of the data set', \n",
    "      'X input:', X.shape, \n",
    "      'y target property:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e910b-179c-402b-8fb9-d75b6ee63890",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to visualize the evolution of the training \n",
    "def plot_active_learning_results(performance: list, set_sizes: list, model_name: str):\n",
    "    \"\"\"\n",
    "    Plots with the performance evolution during the active learning\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot 1: Performance vs. Iterations\n",
    "    ax1.plot(range(1, len(performance) + 1), performance, 'bo-', label=model_name)\n",
    "    ax1.set_xlabel(\"Iteration\")\n",
    "    ax1.set_ylabel(\"Test Score (RÂ²)\")\n",
    "    ax1.set_title(f\"{model_name} Performance\")\n",
    "    ax1.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot 2: Training Set Size Growth\n",
    "    ax2.plot(range(1, len(set_sizes) + 1), set_sizes, 'ro-')\n",
    "    ax2.set_xlabel(\"Iteration\")\n",
    "    ax2.set_ylabel(\"Training Set Size\")\n",
    "    ax2.set_title(\"Active Learning: Training Set Growth\")\n",
    "    ax2.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c2997-1429-43ab-8241-1e679ef3a625",
   "metadata": {},
   "source": [
    "### 2.2. Select the parameters to initiate and query the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6840c8f9-619f-463f-bec6-39c06da79898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of data points to initialize the first model\n",
    "n_initial = 50\n",
    "\n",
    "# Number of query instances to retrieve during each Active Learning workflow iteration\n",
    "n_instances_per_query = 5\n",
    "\n",
    "# Total number of Active Learning cycles/iterations to perform\n",
    "n_iterations = 35 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc450c3-034d-40e1-9484-723ee69af0c9",
   "metadata": {},
   "source": [
    "### 2.3. Split dataset into: initial, pool, and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb383bd2-727c-4086-a242-8576a73db143",
   "metadata": {},
   "source": [
    "The data is divided into three distinct sets: 1) a training set to build the initial model, 2) a pool set from which data points can be selected for labeling, and 3) a test set to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6cd258-6b87-401c-a5b7-cd98ffe5ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Set aside a test set\n",
    "X_rest, X_test, y_rest, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: From rest, sample initial training data\n",
    "initial_idx = np.random.choice(range(len(X_rest)), size=n_initial, replace=False)\n",
    "X_initial = X_rest[initial_idx]\n",
    "y_initial = y_rest[initial_idx]\n",
    "\n",
    "# Step 3: Everything else becomes the pool\n",
    "mask = np.ones(len(X_rest), dtype=bool)\n",
    "mask[initial_idx] = False\n",
    "X_pool = X_rest[mask]\n",
    "y_pool = y_rest[mask]\n",
    "\n",
    "print(len(X_pool), len(y_pool))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d116a008-077e-4453-a727-d66a11a2132a",
   "metadata": {},
   "source": [
    "### 2.4. Linear Regression: building and initial set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c8b74-3bfe-493c-b5fa-f9f24f3efb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a linear regression model on the initial dataset\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_initial, y_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c5935b-5a08-4e72-bec6-7c8d8791c6e9",
   "metadata": {},
   "source": [
    "### 2.5. Linear Regression: query strategy and learner definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cf835a-839f-472a-a7f1-6705a8d439fa",
   "metadata": {},
   "source": [
    "In this cell, we define a custom query strategy for the active learning process using a linear regression model. The `mse_query_strategy` function calculates the individual squared errors for each instance in the pool and identifies the indices of the instances with the highest errors, indicating they are the most informative to query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec723a1-72e8-4d5d-b375-d4dd22dc54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_query_strategy(classifier, X, n_instances=n_instances_per_query):\n",
    "    \n",
    "    y_pred = classifier.predict(X)\n",
    "    individual_mse = (y_pred - np.mean(y_pred))**2  # This gives squared errors per instance\n",
    "    query_idx, _ = multi_argmax(individual_mse.flatten(), n_instances=n_instances)  #  indices to query in the pool\n",
    "\n",
    "    return query_idx\n",
    "\n",
    "# Create an active learner for Linear Regression using the modAL library\n",
    "lin_learner = ActiveLearner(estimator=lin_reg, \n",
    "                            query_strategy=mse_query_strategy, \n",
    "                            X_training=X_initial, \n",
    "                            y_training=y_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb875fa0-f7f9-4d13-8a29-5f78bc313f81",
   "metadata": {},
   "source": [
    "### 2.6. Linear Regression: active learning workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e634752-103c-4f3c-b2c2-f0e8a11b11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Current X_training shape:\", lin_learner.X_training.shape)\n",
    "print(\"Current y_training shape:\", lin_learner.y_training.shape)\n",
    "print(\"X shape:\", X_pool.shape)\n",
    "print(\"y_pool shape:\", y_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f7fb6-5a1a-46bb-ba7c-7f0eccc1e87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform active learning\n",
    "lin_performance = []\n",
    "training_set_sizes = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    print(f'Iteration {i+1}')\n",
    "    # Query from available points\n",
    "    query_idx_lin, _ = lin_learner.query(X_pool, n_instances=n_instances_per_query)\n",
    "    print('   Query length', len(query_idx_lin))\n",
    "    print('   Indices to query from the pool', query_idx_lin)\n",
    "    print()\n",
    "     \n",
    "    # Obtain the label from the oracle\n",
    "    query_label_lin = y_pool[query_idx_lin].reshape(-1,)\n",
    "    query_instance_lin = X_pool[query_idx_lin]\n",
    "    \n",
    "    # Teach augments the available training data with the new samples\n",
    "    lin_learner.teach(X=query_instance_lin, y=query_label_lin)\n",
    "\n",
    "    # Evaluate the model performance on the test set\n",
    "    lin_score = lin_learner.score(X_test, y_test)\n",
    "\n",
    "    # Print the results and append the scores to the performance lists\n",
    "\n",
    "    print(f\"   Linear Regression Test Score RÂ²: {lin_score:.4f}\")\n",
    "    print(f\"   Current training set size, X: {len(lin_learner.X_training)}, y:, {len(lin_learner.y_training)}\")\n",
    "    \n",
    "    # Optionally remove these from pool\n",
    "    X_pool = np.delete(X_pool, query_idx_lin, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx_lin, axis=0)\n",
    "\n",
    "    training_set_sizes.append(len(lin_learner.X_training))\n",
    "    lin_performance.append(lin_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae745d-7bd3-413a-8a4d-9cd507edcabf",
   "metadata": {},
   "source": [
    "### 2.7. Linear Regression: evaluating the evolution of performance in the AL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691239f-fe82-40b4-bbb7-a0be401dcb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_active_learning_results(lin_performance, training_set_sizes, model_name = 'Linear Regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d96b8-aa7c-4a98-835a-930c01093efe",
   "metadata": {},
   "source": [
    "### 2.8. Gaussian Processes: query strategy and learner definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2609a6f8-eef6-499d-bf33-b9d36b88c8db",
   "metadata": {},
   "source": [
    "In this cell, we define a custom query strategy for the AL workflow utilizing Gaussian Process (GP) regression. The `GP_regression_std` function selects instances based on their predicted uncertainty, which is an essential aspect of active learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f864282-ffca-4512-b9cb-a1df6c2d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF\n",
    "\n",
    "# setting the query strategy\n",
    "def GP_regression_std(regressor, X_sample, n_instances=1):\n",
    "\n",
    "    y_pred, std = regressor.predict(X_sample, return_std=True, )\n",
    "    query_idx, _ = multi_argmax(std.flatten(), n_instances=n_instances)     # Select instances with highest uncertainty\n",
    "\n",
    "    return query_idx\n",
    "\n",
    "kernel = RBF(length_scale=1.0, length_scale_bounds=(1e-2, 1e3)) \\\n",
    "         + WhiteKernel(noise_level=1, noise_level_bounds=(1e-10, 1e+1))\n",
    "\n",
    "GP_learner = ActiveLearner(estimator=GaussianProcessRegressor(kernel=kernel),\n",
    "                            query_strategy=GP_regression_std,\n",
    "                            X_training=X_initial,\n",
    "                            y_training=y_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfaa8da6-a254-4a50-8e80-28e929d601a5",
   "metadata": {},
   "source": [
    "### 2.9. GP: active learning worflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feafa229-be03-4abf-b44d-200993cc76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set again to avoid overwriting\n",
    "mask = np.ones(len(X_rest), dtype=bool)\n",
    "mask[initial_idx] = False\n",
    "X_pool = X_rest[mask]\n",
    "y_pool = y_rest[mask]\n",
    "\n",
    "print(len(X_pool), len(y_pool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7dff08-d2e9-4f9a-a37d-7561e2ac4623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform active learning using Gaussian Processes\n",
    "GP_performance = []\n",
    "training_set_sizes_GP = []\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    print(f'Iteration {i+1}')\n",
    "    # Query the most uncertain data point for each model\n",
    "    query_idx_GP, query_instance_GP = GP_learner.query(X_pool,  n_instances=n_instances_per_query)\n",
    "    print('   Query length', len(query_idx_GP))\n",
    "    print('   Indices to query from the pool', query_idx_GP)\n",
    "    print()\n",
    "    \n",
    "    # Obtain the label from the oracle\n",
    "    query_label_GP = y_pool[query_idx_GP].reshape(-1,)\n",
    "    query_instance_GP = X_pool[query_idx_GP]\n",
    "    \n",
    "    # Teach augments the available training data with the new samples\n",
    "    GP_learner.teach(X=query_instance_GP, y=query_label_GP) # y[query_idx_GP].reshape(1, -1))\n",
    "\n",
    "    # Evaluate the model performance on the test set\n",
    "    GP_score = GP_learner.score(X_test, y_test)\n",
    "\n",
    "    print(f\"   GP Regression Test Score RÂ²: {GP_score:.4f}\")\n",
    "    print(f\"   Current training set size, X: {len(GP_learner.X_training)}, y:, {len(GP_learner.y_training)}\")\n",
    "    \n",
    "    # Optionally remove these from pool\n",
    "    X_pool = np.delete(X_pool, query_idx_GP, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx_GP, axis=0)\n",
    "     \n",
    "    GP_performance.append(GP_score)\n",
    "    training_set_sizes_GP.append(len(GP_learner.X_training))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5e3fa-6926-48b5-9a94-484e302e7d6b",
   "metadata": {},
   "source": [
    "### 2.10. GP: evaluating the evolution of performance in the AL workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1382ac8-a86f-461e-b1fb-c8347a350746",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_active_learning_results(GP_performance, training_set_sizes_GP, model_name='Gaussian Processes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277188a-a425-4967-a9b3-4c89a90c3ba5",
   "metadata": {},
   "source": [
    "### 2.11. Comparison Linear Regression vs. GPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50509ec-d7be-4551-88f7-edfb2a2888cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test set predictions\n",
    "y_pred_lin = lin_learner.predict(X_test)  # Linear model\n",
    "y_pred_gp, _ = GP_learner.predict(X_test, return_std=True)  # GP model (mean prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e98df32-a5b0-4033-bb6b-aebe0142800e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the predictions with linear and GPs\n",
    "print(\"Comparison of the results:\")\n",
    "print(f\"  Linear Regression Test Score (RÂ²): {lin_score:.4f}\")\n",
    "print(f\"  Gaussian Process Test Score (RÂ²): {GP_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aa3338-14a7-4311-ad27-8e4a841a950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plot Linear Regression predictions\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_pred_lin, alpha=0.5, c='orange', label='Linear Regression')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)  # Diagonal line\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.text(0.05, 0.9, f'RÂ² = {lin_score:.3f}', transform=plt.gca().transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.title('Linear Regression: True vs Predicted')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Gaussian Process predictions\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(y_test, y_pred_gp, alpha=0.5, c='violet', label='Gaussian Process')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.text(0.05, 0.9, f'RÂ² = {GP_score:.3f}', transform=plt.gca().transAxes,\n",
    "         bbox=dict(facecolor='white', alpha=0.8))\n",
    "plt.title('Gaussian Process: True vs Predicted')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da436e27-5cc4-4443-9da7-25302c627d99",
   "metadata": {},
   "source": [
    "### 2.12. Next Steps: Experimenting with Active Learning Parameters\n",
    "\n",
    "Now that youâ€™ve observed the predictions from both models (Linear Regression and Gaussian Process) under the current active learning strategy, you can explore how adjusting parameters affects performance. Focus on the initialization and querying logic in **Section 2.2** of your notebook, where you:\n",
    "\n",
    "    Define the initial training set (X_initial, y_initial),\n",
    "\n",
    "    Set the number of query points (e.g., n_instances_per_query),\n",
    "\n",
    "    Define the pool (X_pool, y_pool).\n",
    "\n",
    "Key Parameters to Tune\n",
    "1. **n_initial**\tSize of the starting labeled set\t10, 20, 50\n",
    "2. **n_instances_per_query** Number of points queried per iteration\t1, 5, 10\n",
    "\n",
    "How to Proceed\n",
    "\n",
    "    Modify parameters in Section 2.2, then re-run all subsequent cells (to avoid dataset/state corruption).\n",
    "    \n",
    "    Compare results using your plot_active_learning_results() function.\n",
    "    \n",
    "    Observe trade-offs:\n",
    "    \n",
    "        Smaller n_initial â†’ Faster but risk poor initial performance.\n",
    "        Larger n_instances_per_query â†’ Faster convergence but may select redundant points.\n",
    "\n",
    "**NB!** Always re-run from Section 2.2 after changes to ensure clean experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7439b6fc-ab91-4fbc-9646-947ad88b0766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscodetestjp",
   "language": "python",
   "name": "vscodetestjp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
